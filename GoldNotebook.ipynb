{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7906a38b-5c2a-4028-9b96-a766a9186da6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d0fd440c-faa4-4329-9bc1-b922c73e29d6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "source_object = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b4658ef8-9972-49f4-a56b-37972b889446",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "cdc_col = \"modified_date\"\n",
    "backdated_refresh = \"\"\n",
    "target_schema = \"gold\"\n",
    "target_object = \"dim_flights\"\n",
    "source_schema = \"silver\"\n",
    "source_object = \"silver_flights\"\n",
    "key_cols_list = eval('[\"flight_id\"]')\n",
    "surrogate_key = \"dim_flights_key\"\n",
    "\n",
    "if not backdated_refresh:\n",
    "    if spark.catalog.tableExists(f\"workspace.{target_schema}.{target_object}\"):\n",
    "        last_load = spark.sql(f\"select max({cdc_col}) from workspace.{target_schema}.{target_object}\").collect()[0][0]\n",
    "\n",
    "    else:\n",
    "        last_load = \"1900-01-01 00:00:00\"\n",
    "else:\n",
    "    last_load = backdated_refresh\n",
    "\n",
    "last_load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c85cc23d-6253-4183-82aa-81c605edb8ff",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "if spark.catalog.tableExists(f\"workspace.{target_schema}.{target_object}\"):\n",
    "\n",
    "    key_cols_string_incremental = \", \".join(key_cols_list)\n",
    "    df_target = spark.sql(f\"SELECT {key_cols_string_incremental}, {surrogate_key}, create_date, update_date FROM workspace.{target_schema}.{target_object}\")\n",
    "\n",
    "else:\n",
    "\n",
    "    key_cols_string_init = \", \".join([f\"'' AS {i}\" for i in key_cols_list])\n",
    "\n",
    "    df_target = spark.sql(\n",
    "        f\"SELECT {key_cols_string_init}, 0 as {surrogate_key}, CAST('1900-01-01 00:00:00' as timestamp) as create_date, CAST('1900-01-01 00:00:00' as timestamp) as update_date FROM (SELECT 1) tmp WHERE 1=0\"\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ee734bb7-a12b-4153-8ba9-4ba0d289f4b0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_src = spark.sql(f\"SELECT * FROM {source_schema}.{source_object} WHERE {cdc_col} > '{last_load}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d703e2dd-6a2c-4458-b0d4-3354ccff970b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_src.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cbad8556-08b9-4c1b-82fb-2f7de616db1a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "join_condition = \" AND \".join(f\"src.{i} = trg.{i}\" for i in key_cols_list)\n",
    "\n",
    "\n",
    "df_src.createOrReplaceTempView(\"src\")\n",
    "df_target.createOrReplaceTempView(\"trg\")\n",
    "\n",
    "df_join = spark.sql(f\"\"\"\n",
    "          SELECT src.*,\n",
    "            trg.{surrogate_key},\n",
    "            trg.create_date,\n",
    "            trg.update_date\n",
    "          FROM src\n",
    "          LEFT JOIN trg\n",
    "          ON {join_condition}\n",
    "          \n",
    "          \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "02afe92b-07b6-4611-b355-f08754b47551",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_join.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "75ff576a-717f-4759-a2ad-10c382908ea0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# old records\n",
    "df_old = df_join.filter(col(f'{surrogate_key}').isNotNull())\n",
    "df_old_enriched = df_old.withColumn('update_date', current_timestamp())\n",
    "\n",
    "# new records\n",
    "df_new = df_join.filter(col(f'{surrogate_key}').isNull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "be18dbeb-34e1-43a2-ba1b-596b67fa4276",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "if spark.catalog.tableExists(f\"workspace.{target_schema}.{target_object}\"):\n",
    "    max_surrogate_key = spark.sql(\n",
    "        f\"SELECT max({surrogate_key}) FROM workspace.{target_schema}.{target_object}\"\n",
    "                                  ).collect()[0][0]\n",
    "    df_new_enriched = df_new.withColumn(f\"{surrogate_key}\", lit(max_surrogate_key) + 1 + monotonically_increasing_id())\\\n",
    "        .withColumn('create_date', current_timestamp())\\\n",
    "        .withColumn('update_date', current_timestamp())\n",
    "\n",
    "else:\n",
    "    df_new_enriched = df_new.withColumn(f\"{surrogate_key}\", 1 + monotonically_increasing_id())\\\n",
    "        .withColumn('create_date', current_timestamp())\\\n",
    "        .withColumn('update_date', current_timestamp())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4459d961-7942-4100-b376-90c174ec8f05",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "max_surrogate_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0e20d0e4-c65a-4b42-85b5-bbc8dcc7612f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_union = df_old_enriched.unionByName(df_new_enriched)\n",
    "\n",
    "df_union.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "755a1738-4e8e-481c-b671-ca911f9efe03",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# upsert\n",
    "# modified_date is used as the condition for upsert - source of truth for records\n",
    "\n",
    "from delta.tables import DeltaTable\n",
    "\n",
    "if spark.catalog.tableExists(f\"workspace.{target_schema}.{target_object}\"):\n",
    "\n",
    "    dlt_object = DeltaTable.forName(spark, f\"workspace.{target_schema}.{target_object}\")\n",
    "\n",
    "    dlt_object.alias(\"trg\").merge(df_union.alias(\"src\"),\n",
    "        f\"trg.{surrogate_key} = src.{surrogate_key}\"\n",
    "    ).whenMatchedUpdateAll(condition=f\"src.{cdc_col} >= trg.{cdc_col}\")\\\n",
    "        .whenNotMatchedInsertAll()\\\n",
    "            .execute()\n",
    "\n",
    "else:\n",
    "\n",
    "    df_union.write\\\n",
    "        .format(\"delta\")\\\n",
    "            .mode(\"append\")\\\n",
    "                .saveAsTable(f\"workspace.{target_schema}.{target_object}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "927adbbf-800c-4299-ac30-243078510854",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT * FROM `workspace`.`gold`.`dim_flights`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fc5838f8-fb48-4cf3-8bed-c1fa38860e6d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Records are upserted correctly \n",
    "#  "
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 8722409968820788,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "GoldNotebook",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
